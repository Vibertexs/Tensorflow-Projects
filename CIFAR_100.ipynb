{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR-100.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN0/iLn/f/uXVCWj9YF1+Zb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vibertexs/Tensorflow-Projects/blob/main/CIFAR_100.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ul8wIa5FPqnY"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "\r\n",
        "from tensorflow.keras import datasets, layers, models\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1j4ySvHxJcI"
      },
      "source": [
        "import keras\r\n",
        "from keras.datasets import cifar100\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\r\n",
        "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\r\n",
        "from keras.optimizers import SGD\r\n",
        "from keras.regularizers import l2\r\n",
        "from keras.callbacks import Callback, LearningRateScheduler, TensorBoard, ModelCheckpoint\r\n",
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "# from keras.utils import print_summary, to_categorical\r\n",
        "from keras import backend as K\r\n",
        "import sys\r\n",
        "import os\r\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wIqc9N5graX"
      },
      "source": [
        "# Constants\r\n",
        "BATCH_SIZE = 100\r\n",
        "NUM_CLASSES = 100\r\n",
        "EPOCHS = 165000\r\n",
        "INIT_DROPOUT_RATE = 0.5\r\n",
        "MOMENTUM_RATE = 0.9\r\n",
        "INIT_LEARNING_RATE = 0.01\r\n",
        "L2_DECAY_RATE = 0.0005\r\n",
        "VERBOSE=1\r\n",
        "CROP_SIZE = 32\r\n",
        "VALIDATION_SPLIT = 0.2\r\n",
        "LOG_DIR = './logs'\r\n",
        "MODEL_PATH = './models/keras_cifar100_model.h5'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TP-Mm5fFS0LL"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = cifar100.load_data()\r\n",
        "\r\n",
        "print('X_train shape:', X_train.shape)\r\n",
        "print(X_train.shape[0], 'train samples')\r\n",
        "print(X_test.shape[0], 'test samples')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EQSJkNSTTMm"
      },
      "source": [
        "# Converting the why to categorical\r\n",
        "Y_train = tf.keras.utils.to_categorical(y_train, NUM_CLASSES)\r\n",
        "Y_test = tf.keras.utils.to_categorical(y_test, NUM_CLASSES)\r\n",
        "\r\n",
        "\r\n",
        "x_train = X_train.astype('float32')\r\n",
        "x_test = X_test.astype('float32')\r\n",
        "x_train /= 255.0\r\n",
        "x_test /= 255.0"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DW7FwOfTTPA"
      },
      "source": [
        "# MODEL STRUCTURE FROM https://medium.com/@birdortyedi_23820/deep-learning-lab-episode-5-cifar-100-a557e19219ba\r\n",
        "model = Sequential()\r\n",
        "model.add(ZeroPadding2D(4, input_shape=x_train.shape[1:]))\r\n",
        "model.add(Conv2D(384, (3, 3), padding='same', kernel_regularizer=l2(0.01)))\r\n",
        "model.add(Activation('elu'))\r\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\r\n",
        "model.add(Dropout(INIT_DROPOUT_RATE))\r\n",
        "\r\n",
        "model.add(Conv2D(384, (1, 1), padding='same', kernel_regularizer=l2(L2_DECAY_RATE)))\r\n",
        "model.add(Conv2D(384, (2, 2), padding='same', kernel_regularizer=l2(L2_DECAY_RATE)))\r\n",
        "model.add(Conv2D(640, (2, 2), padding='same', kernel_regularizer=l2(L2_DECAY_RATE)))\r\n",
        "model.add(Conv2D(640, (2, 2), padding='same', kernel_regularizer=l2(L2_DECAY_RATE)))\r\n",
        "model.add(Activation('elu'))\r\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\r\n",
        "model.add(Dropout(INIT_DROPOUT_RATE))\r\n",
        "\r\n",
        "model.add(Conv2D(640, (3, 3), padding='same', kernel_regularizer=l2(L2_DECAY_RATE)))\r\n",
        "model.add(Conv2D(768, (2, 2), padding='same', kernel_regularizer=l2(L2_DECAY_RATE)))\r\n",
        "model.add(Conv2D(768, (2, 2), padding='same', kernel_regularizer=l2(L2_DECAY_RATE)))\r\n",
        "model.add(Conv2D(768, (2, 2), padding='same', kernel_regularizer=l2(L2_DECAY_RATE)))\r\n",
        "model.add(Activation('elu'))\r\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\r\n",
        "model.add(Dropout(INIT_DROPOUT_RATE))\r\n",
        "\r\n",
        "model.add(Conv2D(768, (1, 1), padding='same', kernel_regularizer=l2(L2_DECAY_RATE)))\r\n",
        "model.add(Conv2D(896, (2, 2), padding='same', kernel_regularizer=l2(L2_DECAY_RATE)))\r\n",
        "model.add(Conv2D(896, (2, 2), padding='same', kernel_regularizer=l2(L2_DECAY_RATE)))\r\n",
        "model.add(Activation('elu'))\r\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\r\n",
        "model.add(Dropout(INIT_DROPOUT_RATE))\r\n",
        "\r\n",
        "model.add(Conv2D(896, (3, 3), padding='same', kernel_regularizer=l2(L2_DECAY_RATE)))\r\n",
        "model.add(Conv2D(1024, (2, 2), padding='same', kernel_regularizer=l2(L2_DECAY_RATE)))\r\n",
        "model.add(Conv2D(1024, (2, 2), padding='same', kernel_regularizer=l2(L2_DECAY_RATE)))\r\n",
        "model.add(Activation('elu'))\r\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\r\n",
        "model.add(Dropout(INIT_DROPOUT_RATE))\r\n",
        "\r\n",
        "model.add(Conv2D(1024, (1, 1), padding='same', kernel_regularizer=l2(L2_DECAY_RATE)))\r\n",
        "model.add(Conv2D(1152, (2, 2), padding='same', kernel_regularizer=l2(L2_DECAY_RATE)))\r\n",
        "model.add(Activation('elu'))\r\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\r\n",
        "model.add(Dropout(INIT_DROPOUT_RATE))\r\n",
        "\r\n",
        "model.add(Conv2D(1152, (1, 1), padding='same', kernel_regularizer=l2(L2_DECAY_RATE)))\r\n",
        "model.add(Activation('elu'))\r\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\r\n",
        "model.add(Dropout(INIT_DROPOUT_RATE))\r\n",
        "\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(NUM_CLASSES))\r\n",
        "model.add(Activation('softmax'))\r\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZzGid4jTTRW"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4osr7XjyTTqC"
      },
      "source": [
        "Model Design"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lx7AVIgRTTVc"
      },
      "source": [
        "opt = SGD(lr=INIT_LEARNING_RATE, momentum=MOMENTUM_RATE)\r\n",
        "model.compile(optimizer=opt,\r\n",
        "              loss='categorical_crossentropy',\r\n",
        "              metrics=['accuracy', 'top_k_categorical_accuracy'])\r\n",
        "model.fit(X_train, Y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_split=VALIDATION_SPLIT, verbose= VERBOSE)\r\n",
        "score = model.evaluate(X_test, Y_test, batch_size=BATCH_SIZE, verbose=VERBOSE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWQ1qfx2ThQE"
      },
      "source": [
        "print(\"Test Score:\", score[0])\r\n",
        "print(\"Test Accuracy:\", score[1])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}